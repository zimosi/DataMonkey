# Auto ML Analysis Pipeline

An AI-powered CSV analysis system that uses LangGraph and OpenAI to provide intelligent insights about your datasets.

## ğŸ¯ What This Does

Upload a CSV file â†’ LangGraph processes it â†’ OpenAI analyzes it â†’ Get comprehensive insights!

## ğŸ“ Project Structure

```
studioProject/
â”œâ”€â”€ auto_ml/                    # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js             # Main upload component
â”‚   â”‚   â””â”€â”€ App.css            # Styling
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ backend/                    # FastAPI backend
    â”œâ”€â”€ main.py                 # API endpoints
    â”œâ”€â”€ config.py               # OpenAI configuration
    â”œâ”€â”€ requirements.txt        # Python dependencies
    â”œâ”€â”€ agents/
    â”‚   â””â”€â”€ summarize_agent.py  # LLM analysis agent
    â”œâ”€â”€ graph/
    â”‚   â””â”€â”€ workflow.py         # LangGraph workflow
    â””â”€â”€ uploads/                # Temporary file storage
```

## ğŸš€ Quick Start

### Backend Setup

1. **Navigate to backend directory:**
   ```bash
   cd backend
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up OpenAI API Key** (Required):
   
   Create a `.env` file in the backend directory:
   ```bash
   echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
   ```
   
   Or create `.env` manually:
   ```env
   OPENAI_API_KEY=sk-proj-...your-key-here...
   OPENAI_MODEL=gpt-3.5-turbo
   OPENAI_MAX_TOKENS=2000
   OPENAI_TEMPERATURE=0.1
   ```
   
   > **Get your API key:** https://platform.openai.com/api-keys

5. **Run the server:**
   ```bash
   python main.py
   ```
   
   Server runs at: `http://localhost:8000`  
   API docs at: `http://localhost:8000/docs`

### Frontend Setup

1. **Navigate to frontend directory:**
   ```bash
   cd auto_ml
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Start the app:**
   ```bash
   npm start
   ```
   
   App opens at: `http://localhost:3000`

## ğŸ’¡ How to Use

1. **Start both servers** (backend on port 8000, frontend on port 3000)
2. **Open** `http://localhost:3000` in your browser
3. **Select** a CSV file using the file picker
4. **Click** "Upload & Analyze"
5. **Wait** for the AI analysis (usually 5-10 seconds)
6. **View** the comprehensive insights from OpenAI!

## ğŸ”„ System Architecture

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚ Uploads CSV â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend     â”‚
â”‚  (Port 3000)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /api/upload
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend    â”‚
â”‚  (Port 8000)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph          â”‚
â”‚  Workflow Engine    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Summarize Agent    â”‚
â”‚  (LLM Analysis)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI API         â”‚
â”‚  (GPT-3.5-turbo)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analysis Results   â”‚
â”‚  Sent to Frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LangGraph Workflow

```
START
  â†“
[Summarize Agent]
  â†“
  â€¢ Reads CSV data
  â€¢ Creates analysis prompt
  â€¢ Calls OpenAI API
  â€¢ Returns insights
  â†“
END
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | Health check |
| `POST` | `/api/upload` | Upload CSV and get AI analysis |

### Upload Response Format

```json
{
  "message": "File uploaded and analyzed successfully.",
  "job_id": "uuid-here",
  "filename": "data.csv",
  "status": "summarized",
  "llm_analysis": "Comprehensive AI analysis text...",
  "data_summary": {
    "rows": 100,
    "columns": 5,
    "column_names": ["col1", "col2", ...]
  },
  "error": null
}
```

## âœ¨ Features

- âœ… **Simple CSV Upload** - Drag & drop or click to upload
- âœ… **LangGraph Integration** - Modular agent-based workflow
- âœ… **AI-Powered Analysis** - OpenAI GPT-3.5-turbo insights
- âœ… **Natural Language Output** - Easy-to-read analysis
- âœ… **Real-time Processing** - Synchronous analysis (no polling needed)
- âœ… **Clean Architecture** - Simplified, maintainable codebase
- âœ… **Modern UI** - Beautiful React interface
- âœ… **CORS Enabled** - Frontend-backend communication
- âœ… **Error Handling** - Graceful error messages

## ğŸ§  What the AI Analyzes

The LLM provides insights on:

1. **Dataset Description** - What the data represents
2. **Key Observations** - Important patterns and trends
3. **Data Insights** - Statistical and business insights
4. **ML Suggestions** - Potential machine learning tasks
5. **Data Quality** - Issues and recommendations

## ğŸ”§ Technologies

| Layer | Technology |
|-------|-----------|
| **Frontend** | React 19, Modern CSS |
| **Backend** | FastAPI, Python 3.13 |
| **Workflow** | LangGraph |
| **AI** | OpenAI GPT-3.5-turbo |
| **Data** | Pandas |
| **Async** | asyncio, async/await |

## ğŸ“¦ Dependencies

### Backend (`requirements.txt`)
```
fastapi
uvicorn
python-multipart
pandas
langgraph
langchain
langchain-openai
openai
python-dotenv
```

### Frontend (`package.json`)
```
react: ^19.0.0
react-dom: ^19.0.0
```

## ğŸ“ Key Concepts

### LangGraph
- **StateGraph**: Defines the workflow structure
- **Nodes**: Individual processing units (agents)
- **Edges**: Connections between nodes
- **State**: Data that flows through the graph

### Workflow State
```python
class WorkflowState(TypedDict):
    job_id: str
    file_path: str
    filename: str
    raw_data: pd.DataFrame
    llm_analysis: Optional[str]
    data_summary: Optional[Dict]
    error: Optional[str]
    status: str
    started_at: datetime
    completed_at: Optional[datetime]
```

### Agent Pattern
Each agent:
1. Receives state
2. Processes data
3. Updates state
4. Returns state

## ğŸš§ Future Enhancements

- [ ] Add preprocessing agent (data cleaning)
- [ ] Add model selection agent
- [ ] Add training agent
- [ ] Add evaluation agent
- [ ] Add conditional branching in workflow
- [ ] Add streaming responses
- [ ] Add result visualization charts
- [ ] Add data export functionality
- [ ] Add user authentication
- [ ] Add job history and persistence

## ğŸ› Troubleshooting

### "OPENAI_API_KEY environment variable is required"
- Make sure `.env` file exists in `backend/` directory
- Check that the API key is valid and has no extra spaces/newlines
- Verify the file is named exactly `.env` (not `.env.txt`)

### "Module not found" errors
- Activate the virtual environment: `source venv/bin/activate`
- Install dependencies: `pip install -r requirements.txt`

### Frontend can't connect to backend
- Ensure backend is running on port 8000
- Check CORS settings in `main.py`
- Verify frontend is using `http://localhost:8000`

### OpenAI API quota exceeded
- Check your OpenAI account billing
- Add credits at https://platform.openai.com/account/billing
- Consider using `gpt-3.5-turbo` instead of `gpt-4`

## ğŸ“ License

This project is for educational purposes.

## ğŸ¤ Contributing

This is a learning project. Feel free to fork and experiment!

---

**Built with â¤ï¸ using LangGraph and OpenAI**